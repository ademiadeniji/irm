# @package agent
_target_: agent.ddpg.DDPGAgent
name: ddpg
reward_free: ${reward_free}
obs_type: ??? # to be specified later
obs_shape: ??? # to be specified later
action_shape: ??? # to be specified later
device: ${device}
lr: 1e-4
critic_target_tau: 0.01
update_every_steps: 2
use_tb: ${use_tb}
use_wandb: ${use_wandb}
num_expl_steps: ??? # to be specified later
hidden_dim: 1024
feature_dim: 50
stddev_schedule: 0.2
stddev_clip: 0.3
nstep: 3
batch_size: 1024 # 256 for pixels
init_critic: true
extr_reward: walker_run
extr_reward_seq: []
noise: 1
learnable_reward_scale: false
matching_metric: 'epic'
epic_gradient_descent_steps: ${epic_gradient_descent_steps}
num_cem_iterations: ${num_cem_iterations}
num_cem_samples: ${num_cem_samples}
num_cem_elites: ${num_cem_elites}
z_lr: 5e-3