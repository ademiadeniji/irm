defaults:
  - agent: ddpg
  - irm: irm_cem
  - override hydra/launcher: submitit_local

# mode
reward_free: false
# task settings
domain: jaco
task: walker_stand
use_handcrafted_task_reward: false
use_custom: false
obs_type: states # [states, pixels]
frame_stack: 3 # only works if obs_type=pixels
action_repeat: 1 # set to 2 for pixels
discount: 0.99
time_limit: 200
use_time_limit: false
random_reset: false
# train settings
num_train_frames: 100010
num_seed_frames: 4000
# eval settings
eval_every_frames: 1000
num_eval_episodes: 10
num_plot: 5
# experiment
experiment_folder: test
experiment_name: test
# snapshot
snapshots: [1000, 100000, 500000, 1000000, 1500000, 2000000]
snapshot_dir: ./pretrained_model
# restore
restore_snapshot_dir: ''
restore_snapshot_ts: 100000
# replay buffer
# frames_to_collect: 4000 # set this to be the same as num_train_frames to continuously collect
replay_buffer_size: 1000000
replay_buffer_num_workers: 4
batch_size: ${agent.batch_size}
nstep: ${agent.nstep}
# misc
seed: 1
device: cuda:0
save_video: true
save_train_video: false
use_tb: true
use_wandb: false

hrl: false
replay_dir: ''
update_skill_every_step: 50

hydra:
  run:
    dir: ./experiments/finetune/${experiment_folder}/${experiment_name}/${irm.name}/seed${seed}
  sweep:
    dir: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 160
    nodes: 1
    submitit_folder: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}/.slurm
